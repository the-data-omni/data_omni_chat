{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV file from: jumped_up_test.csv\n",
      "CSV loaded successfully.\n",
      "\n",
      "Sending request to CodeLlama at: http://localhost:11434/api/chat\n",
      "\n",
      "--- CodeLlama's Data Cleanup Suggestions ---\n",
      "\n",
      "Based on the provided information, here are some potential structural issues and suggested changes:\n",
      "\n",
      "1. Potential structural issues:\n",
      "* The data has a lot of missing values (7 non-null values out of 7 entries). This can make it difficult to analyze the data as there may be bias towards certain groups or values.\n",
      "* The data has a lot of duplicated values, which can also cause bias in analysis.\n",
      "* The data types for all columns are strings, which can limit the type of analysis that can be performed on them. For example, if the age column were to be numeric, it would be easier to analyze and compare values.\n",
      "2. Mispaced column names:\n",
      "* The column \"Name\" appears twice in the first row, which may cause confusion when reading the data. It is best to have consistent column names throughout the dataset.\n",
      "3. Suggested structural transformations:\n",
      "* Convert all columns to strings, as this will enable more flexible and extensible analysis. For example, if the age column were to be numeric, it would be easier to analyze and compare values.\n",
      "* Use a data cleaning technique such as filling in missing values with a placeholder or imputing them using a statistical method. This can help reduce bias towards certain groups or values.\n",
      "* Use a data transformation technique such as normalizing or scaling the data to improve its representation and make it easier to analyze. For example, if the age column were to be numeric, it would be easier to analyze and compare values.\n",
      "* Consider using a data validation technique to ensure that the data is consistent and meets certain requirements, such as ensuring that all columns are present and have the correct data type.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import io # To represent DataFrame as string\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Ollama/CodeLlama Endpoint Configuration\n",
    "BASE_URL = \"http://localhost:11434\"  # Or your CodeLlama server URL\n",
    "API_PATH = \"/api/chat\"              # Or \"/api/generate\" if you prefer\n",
    "CODELAMA_MODEL = \"codellama:7b\"     # Your specific CodeLlama model\n",
    "\n",
    "# 2. CSV File Path\n",
    "#    Replace 'your_data.csv' with the actual path to your CSV file.\n",
    "#    If the CSV is in the same directory as your notebook, just the filename is fine.\n",
    "CSV_FILE_PATH = 'jumped_up_test.csv' # <--- !!! IMPORTANT: UPDATE THIS PATH !!!\n",
    "\n",
    "# --- Helper Function to Prepare DataFrame Info for LLM ---\n",
    "def get_dataframe_info_for_prompt(df, num_rows_to_show=5):\n",
    "    \"\"\"\n",
    "    Generates a string representation of DataFrame info (header, dtypes, head)\n",
    "    to be included in the LLM prompt.\n",
    "    \"\"\"\n",
    "    header = \", \".join(df.columns.tolist())\n",
    "    \n",
    "    # Get dtypes as a string\n",
    "    dtypes_buffer = io.StringIO()\n",
    "    df.info(buf=dtypes_buffer)\n",
    "    dtypes_str = dtypes_buffer.getvalue()\n",
    "\n",
    "    # Get a sample of the data (first few rows) as a string\n",
    "    sample_data_str = df.head(num_rows_to_show).to_string()\n",
    "\n",
    "    info = f\"CSV Columns (Header): {header}\\n\\n\"\n",
    "    info += f\"Data Types and Non-Null Counts:\\n{dtypes_str}\\n\\n\"\n",
    "    info += f\"First {num_rows_to_show} rows of data:\\n{sample_data_str}\\n\"\n",
    "    return info\n",
    "\n",
    "# --- Main Logic ---\n",
    "try:\n",
    "    # 1. Load the CSV into a pandas DataFrame\n",
    "    print(f\"Loading CSV file from: {CSV_FILE_PATH}\")\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_FILE_PATH)\n",
    "        print(\"CSV loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: CSV file not found at '{CSV_FILE_PATH}'. Please check the path.\")\n",
    "        # Create a dummy DataFrame for demonstration if file not found,\n",
    "        # so the rest of the script can run. Replace with your error handling.\n",
    "        print(\"Using a dummy DataFrame for demonstration purposes.\")\n",
    "        data = {'col1': [1, 2, None, 4, '  '],\n",
    "                'col2': ['a', 'b', 'c', ' d ', 'e'],\n",
    "                'date_col': ['2023-01-01', '2023-01-02', '2023-01-03', '2023/01/04', 'invalid_date'],\n",
    "                'numeric_col_as_str': ['100', '200.5', '300', 'Nan', '500']}\n",
    "        df = pd.DataFrame(data)\n",
    "        print(\"Dummy DataFrame created.\")\n",
    "\n",
    "\n",
    "    # 2. Get DataFrame information for the prompt\n",
    "    dataframe_details = get_dataframe_info_for_prompt(df, num_rows_to_show=3) # Show 3 rows for brevity\n",
    "\n",
    "    # 3. Construct the prompt for CodeLlama\n",
    "    prompt_text = (\n",
    "        f\"I have a dataset with the following structure and a sample of the data:\\n\\n\"\n",
    "        f\"{dataframe_details}\\n\\n\"\n",
    "        f\"Based on these column names, data types, and sample values, please describe:\\n\"\n",
    "        f\"1. Potential structural issues.\\n\"\n",
    "        f\"2. Identify any mispaced column names.and state the column names\\n\"\n",
    "        f\"tate structural transformations required to make the data analytics ready.\"\n",
    "    )\n",
    "\n",
    "    # 4. Prepare the payload for the LLM\n",
    "    if \"chat\" in API_PATH:\n",
    "        payload = {\n",
    "            \"model\": CODELAMA_MODEL,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt_text}\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            # \"options\": {\n",
    "            #     \"temperature\": 0.3, # Lower temperature for more factual/less creative cleaning suggestions\n",
    "            #     \"num_predict\": 500  # Max tokens for the response\n",
    "            # }\n",
    "        }\n",
    "    else: # For /api/generate\n",
    "        payload = {\n",
    "            \"model\": CODELAMA_MODEL,\n",
    "            \"prompt\": prompt_text,\n",
    "            \"stream\": False,\n",
    "            # \"options\": { ... }\n",
    "        }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    ENDPOINT_URL = BASE_URL + API_PATH\n",
    "    print(f\"\\nSending request to CodeLlama at: {ENDPOINT_URL}\")\n",
    "    # print(f\"Payload: {json.dumps(payload, indent=2)}\") # Uncomment to see the full payload\n",
    "\n",
    "    # 5. Send the request to CodeLlama\n",
    "    response = requests.post(ENDPOINT_URL, json=payload, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # 6. Process and display the response\n",
    "    result = response.json()\n",
    "    print(\"\\n--- CodeLlama's Data Cleanup Suggestions ---\")\n",
    "\n",
    "    if \"chat\" in API_PATH:\n",
    "        if result.get(\"message\"):\n",
    "            print(result.get(\"message\", {}).get(\"content\"))\n",
    "        else: # Some Ollama versions might return the content directly\n",
    "            print(result.get(\"content\", \"No content found in response message.\"))\n",
    "    elif \"generate\" in API_PATH:\n",
    "        print(result.get(\"response\", \"No response content found.\"))\n",
    "    else:\n",
    "        print(json.dumps(result, indent=2))\n",
    "\n",
    "except FileNotFoundError as fnf_error:\n",
    "    print(fnf_error) # Already handled above but good to have a catch-all\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"ERROR: The CSV file '{CSV_FILE_PATH}' is empty.\")\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "    print(f\"Response content: {response.content.decode()}\")\n",
    "except requests.exceptions.ConnectionError as conn_err:\n",
    "    print(f\"Connection error: {conn_err}\")\n",
    "    print(\"Please ensure your local CodeLlama endpoint is running and accessible at the specified URL.\")\n",
    "except requests.exceptions.RequestException as req_err:\n",
    "    print(f\"Request error occurred: {req_err}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to decode JSON response from CodeLlama.\")\n",
    "    print(f\"Response content: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV file from: example_messy_recipe.csv (assuming no header row initially)\n",
      "CSV loaded successfully with default integer column names.\n",
      "\n",
      "Sending request to CodeLlama (codellama:7b-instruct) to identify headers...\n",
      "\n",
      "--- Raw LLM Response for Headers ---\n",
      "'Based on the provided data snippet, it appears that the actual column headers are present in rows 10 and 11. These rows contain the following values:\n",
      "```\n",
      "Point    Density    Sugar   Ratio            X                Y\n",
      "1  5020.6074  98.6872  0.9976          145                0\n",
      "2  4976.0088  98.1275  0.9955       108.75                0\n",
      "```\n",
      "Therefore, the meaningful header names are:\n",
      "```\n",
      "Point, Density, Sugar, Ratio,'\n",
      "\n",
      "--- Identified Potential Headers (as List) ---\n",
      "['Based on the provided data snippet', 'it appears that the actual column headers are present in rows 10 and 11. These rows contain the following values:\\n```\\nPoint    Density    Sugar   Ratio            X                Y\\n1  5020.6074  98.6872  0.9976          145                0\\n2  4976.0088  98.1275  0.9955       108.75                0\\n```\\nTherefore', 'the meaningful header names are:\\n```\\nPoint', 'Density', 'Sugar', 'Ratio']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import io # To represent DataFrame as string\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Ollama/CodeLlama Endpoint Configuration\n",
    "BASE_URL = \"http://localhost:11434\"  # Or your CodeLlama server URL\n",
    "API_PATH = \"/api/chat\"              # Using chat for more instruction-following capabilities\n",
    "CODELAMA_MODEL = \"codellama:7b-instruct\" # Using an instruct model is often better for this\n",
    "                                     # If you only have base codellama:7b, it might work but instruct is preferred\n",
    "\n",
    "# 2. CSV File Path\n",
    "CSV_FILE_PATH = 'example_messy_recipe.csv' # <--- !!! IMPORTANT: UPDATE THIS PATH !!!\n",
    "\n",
    "# --- Helper Function to Prepare Raw Data Snippet for LLM ---\n",
    "def get_raw_data_snippet(df, num_rows_to_show=15):\n",
    "    \"\"\"\n",
    "    Generates a string representation of the first few rows of the DataFrame,\n",
    "    meant for identifying headers in a headerless load.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return \"No data or empty DataFrame loaded.\"\n",
    "\n",
    "    # Represent the DataFrame's head as a string, keeping the default integer headers\n",
    "    # to show the LLM exactly what pandas loaded.\n",
    "    snippet = df.head(num_rows_to_show).to_string(index=True, header=True)\n",
    "    return snippet\n",
    "\n",
    "# --- Helper Function to Call CodeLlama ---\n",
    "def call_codellama_for_headers(raw_data_snippet, model_name, base_url, api_path):\n",
    "    \"\"\"\n",
    "    Sends a prompt to CodeLlama specifically to identify headers and return them\n",
    "    as a comma-separated string.\n",
    "    \"\"\"\n",
    "    endpoint_url = base_url + api_path\n",
    "\n",
    "    prompt_text = (\n",
    "        f\"You are an expert data analysis assistant. I have loaded a CSV file into a pandas DataFrame \"\n",
    "        f\"using `header=None`, so it currently has default integer column names (0, 1, 2, ...).\\n\"\n",
    "        f\"The actual column headers are likely present in one of the first few data rows.\\n\\n\"\n",
    "        f\"Here are the first few rows of this DataFrame (including the current integer index and integer column names):\\n\"\n",
    "        f\"--- DATA SNIPPET ---\\n\"\n",
    "        f\"{raw_data_snippet}\\n\"\n",
    "        f\"--- END DATA SNIPPET ---\\n\\n\"\n",
    "        f\"Your task is to carefully examine these rows and identify the row that most likely contains the actual column headers. \"\n",
    "        f\"These headers might be jumbled, have extra spaces, or be in a row with some empty/NaN values in other cells that are not part of the header list.\\n\"\n",
    "        f\"Extract only the meaningful header names from that row.\\n\\n\"\n",
    "        f\"**Your entire response MUST be ONLY a comma-separated list of these identified column names.**\\n\"\n",
    "        f\"For example: `ColumnID,ProductName,SaleAmount,TransactionDate`\\n\"\n",
    "        f\"Do NOT include any explanations, apologies, or any other text. Do not use markdown like backticks.\\n\"\n",
    "        f\"If you are highly confident you've found the headers, return them. \"\n",
    "        f\"If you cannot confidently identify a clear header row or the data seems to have no discernible headers in the snippet, return the exact string: `NO_HEADERS_FOUND`\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt_text}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0, # Low temperature for deterministic output\n",
    "            \"num_predict\": 150  # Max tokens for the header list\n",
    "        }\n",
    "    }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    print(f\"\\nSending request to CodeLlama ({model_name}) to identify headers...\")\n",
    "    # print(f\"Prompt Snippet: {prompt_text[:300]}...\") # For debugging\n",
    "    response = requests.post(endpoint_url, json=payload, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "\n",
    "    content = result.get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "    \n",
    "    # Clean up common LLM artifacts if they slip through despite prompt\n",
    "    content = re.sub(r'^[\"\\']?(.*?)[\"\\']?$', r'\\1', content) # Remove leading/trailing quotes\n",
    "    if content.lower().startswith(\"here are the identified headers:\") or \\\n",
    "       content.lower().startswith(\"the identified headers are:\"):\n",
    "        content = content.split(\":\", 1)[-1].strip()\n",
    "    if content.startswith(\"`\") and content.endswith(\"`\"):\n",
    "        content = content[1:-1]\n",
    "\n",
    "\n",
    "    if not content:\n",
    "        print(\"Warning: Received empty content from CodeLlama for headers.\")\n",
    "        return \"NO_HEADERS_FOUND\"\n",
    "    return content\n",
    "\n",
    "# --- Main Logic ---\n",
    "df_loaded = None\n",
    "identified_headers = []\n",
    "try:\n",
    "    # 1. Load the CSV into a pandas DataFrame, ASSUMING NO HEADER\n",
    "    print(f\"Loading CSV file from: {CSV_FILE_PATH} (assuming no header row initially)\")\n",
    "    try:\n",
    "        df_loaded = pd.read_csv(CSV_FILE_PATH, header=None, on_bad_lines='warn', keep_default_na=False, na_filter=False)\n",
    "        # keep_default_na=False, na_filter=False ensures empty strings are read as empty strings, not NaN,\n",
    "        # which can be important for header identification if headers have empty strings.\n",
    "        print(\"CSV loaded successfully with default integer column names.\")\n",
    "        if df_loaded.empty:\n",
    "            print(\"Warning: The loaded DataFrame is empty after initial load. Check your CSV file.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: CSV file not found at '{CSV_FILE_PATH}'. Please check the path.\")\n",
    "        print(\"Using a dummy DataFrame (with header in data) for demonstration purposes.\")\n",
    "        data_for_dummy_csv = [\n",
    "            [\"REPORT TITLE\", \"\", \"\", \"\", \"\"],\n",
    "            [\"Date: 2025-05-22\", \"\", \"\", \"\", \"\"],\n",
    "            [\"\", \"\", \"\", \"\", \"\"], # Blank row\n",
    "            [\"  ITEM ID  \", \" Product Name \", \"  Category \", \" Unit Price \", \" Quantity Sold \"], # Actual header row with spaces\n",
    "            [\"SKU001\", \"Widget Alpha\", \"Electronics\", \"  19.99 \", \"150\"],\n",
    "            [\"SKU002\", \"Gizmo Beta\", \"Gadgets\", \"35.00\", \"  200  \"],\n",
    "            [\"SKU003\", \"Thingamajig Gamma\", \"Accessories\", \"7.50\", \"500\"],\n",
    "            [\"\", \"TOTALS\", \"\", \"62.49\", \"850\"] # Potentially confusing row\n",
    "        ]\n",
    "        df_loaded = pd.DataFrame(data_for_dummy_csv)\n",
    "        print(\"Dummy DataFrame created.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"ERROR: The CSV file '{CSV_FILE_PATH}' is empty. Cannot proceed.\")\n",
    "        exit() # Or handle as appropriate\n",
    "\n",
    "    if df_loaded is not None and not df_loaded.empty:\n",
    "        # 2. Get a snippet of the raw DataFrame data\n",
    "        # Show enough rows to give the LLM a good chance to find headers\n",
    "        raw_data_snippet_for_llm = get_raw_data_snippet(df_loaded, num_rows_to_show=12)\n",
    "\n",
    "        # 3. Call CodeLlama to identify headers\n",
    "        llm_response_headers_str = call_codellama_for_headers(\n",
    "            raw_data_snippet_for_llm, CODELAMA_MODEL, BASE_URL, API_PATH\n",
    "        )\n",
    "\n",
    "        print(f\"\\n--- Raw LLM Response for Headers ---\\n'{llm_response_headers_str}'\")\n",
    "\n",
    "        if llm_response_headers_str.strip().upper() == \"NO_HEADERS_FOUND\" or not llm_response_headers_str.strip():\n",
    "            print(\"\\nLLM indicated no headers were confidently found or returned an empty response.\")\n",
    "        else:\n",
    "            # Parse the comma-separated string into a list\n",
    "            # Also strip whitespace from each potential header\n",
    "            identified_headers = [header.strip() for header in llm_response_headers_str.split(',') if header.strip()]\n",
    "            print(f\"\\n--- Identified Potential Headers (as List) ---\")\n",
    "            print(identified_headers)\n",
    "\n",
    "            if not identified_headers:\n",
    "                 print(\"Parsed header list is empty. LLM might have returned only commas or unexpected format.\")\n",
    "            # Next steps would be to use these identified_headers to find the row,\n",
    "            # set it as header, and clean the DataFrame.\n",
    "            # For example:\n",
    "            # 1. Iterate through df_loaded.head(N).iterrows() to find which row matches these headers.\n",
    "            # 2. If found, new_header_row_index = index\n",
    "            # 3. df_loaded.columns = df_loaded.iloc[new_header_row_index]\n",
    "            # 4. df_loaded = df_loaded[new_header_row_index+1:].reset_index(drop=True)\n",
    "            # This logic is for a subsequent step.\n",
    "\n",
    "    else:\n",
    "        print(\"DataFrame was not loaded or is empty after initial load. Skipping LLM header identification.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as fnf_error:\n",
    "    print(f\"File error: {fnf_error}\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Pandas EmptyDataError: The CSV file '{CSV_FILE_PATH}' might be empty or improperly formatted.\")\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "    if hasattr(http_err, 'response') and http_err.response is not None:\n",
    "        print(f\"Response content: {http_err.response.content.decode()}\")\n",
    "except requests.exceptions.ConnectionError as conn_err:\n",
    "    print(f\"Connection error: {conn_err}\")\n",
    "    print(f\"Please ensure your local CodeLlama endpoint is running and accessible at {BASE_URL}{API_PATH}.\")\n",
    "except requests.exceptions.RequestException as req_err:\n",
    "    print(f\"Request error occurred: {req_err}\")\n",
    "except json.JSONDecodeError as json_err:\n",
    "    print(f\"Failed to decode JSON response from CodeLlama: {json_err}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to analyze image: screenshot.png\n",
      "\n",
      "Sending request to Ollama API at http://localhost:11434/api/generate with model llava:7b...\n",
      "\n",
      "--- LLM Analysis Summary ---\n",
      "1. The dataset appears to be a spreadsheet with rows and columns organized in a structured manner, potentially for inventory management, tracking shipments, or similar activities given the context provided by the column headers. It contains information such as Item Number, Product Name, Description, Quantity in Stock, and various fields related to shipment status and tracking details like Truck ID, Ship Date/Time, and Temperature during transit.\n",
      "2. The visible columns seem to be a mix of inventory management (Item Number, Product Name, Quantity) and shipment tracking (Truck ID, Ship Date/Time). There is also a column with Temperature readings for the goods in transit.\n",
      "3. The column headers are: Item Number, Product Name, Description, Quantity, 2nd Truck ID, 2nd Ship Date/Time, 2nd Temperature, and others that are not fully visible.\n",
      "4. From the visible data, there seems to be a pattern of shipments with consistent tracking information (Truck ID, Ship Date/Time). The temperature readings indicate an ongoing concern for maintaining the required temperature conditions during transit for certain products or categories. However, without more context or columns, it's difficult to draw in-depth conclusions about other aspects of the dataset, such as the specific nature of the goods being transported or the reasons for shipment status and quantity tracking.\n",
      "\n",
      "In summary, this image shows a spreadsheet containing inventory management and shipment tracking information, with fields related to item details, shipping status, and temperature conditions during transit. The data suggests that it is used for tracking inventory and ensuring proper handling of goods during transportation.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Ollama API Configuration\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"  # Or /api/chat if your model prefers\n",
    "# Ensure this is a multimodal model capable of image understanding\n",
    "MULTIMODAL_MODEL_NAME = \"llava:7b\" # Replace with your specific model, e.g., \"llava:13b\"\n",
    "\n",
    "# 2. Image File Path\n",
    "#    Replace 'path/to/your/dataset_screenshot.png' with the actual path to your image.\n",
    "IMAGE_FILE_PATH = 'screenshot.png' # <--- !!! IMPORTANT: UPDATE THIS PATH !!!\n",
    "\n",
    "# --- Helper Function to Encode Image to Base64 ---\n",
    "def encode_image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Opens an image, converts it to base64 string (without data URI prefix).\n",
    "    Handles potential image conversion issues for formats like HEIC by converting to JPEG.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Error: Image file not found at {image_path}\")\n",
    "            return None\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        output_buffer = io.BytesIO()\n",
    "\n",
    "        # Convert to RGB if it's RGBA (to avoid issues with some formats like PNG transparency)\n",
    "        if img.mode == 'RGBA' or img.mode == 'P': # P for palettized images\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        # Determine format and save to buffer\n",
    "        # For simplicity, we'll save as JPEG, which is widely supported.\n",
    "        # You could try to preserve the original format if preferred, but JPEG is safe.\n",
    "        img.save(output_buffer, format=\"JPEG\")\n",
    "        \n",
    "        byte_data = output_buffer.getvalue()\n",
    "        base64_str = base64.b64encode(byte_data).decode('utf-8')\n",
    "        return base64_str\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Main Analysis Logic ---\n",
    "def analyze_dataset_screenshot(image_path, ollama_url, model_name):\n",
    "    \"\"\"\n",
    "    Analyzes a dataset screenshot using a local multimodal LLM via Ollama.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to analyze image: {image_path}\")\n",
    "    base64_image_data = encode_image_to_base64(image_path)\n",
    "\n",
    "    if not base64_image_data:\n",
    "        print(\"Failed to encode image. Aborting analysis.\")\n",
    "        return\n",
    "\n",
    "    prompt_text = (\n",
    "        \"This is an image of a dataset, likely a table or spreadsheet. Please analyze it carefully. Describe:\\n\"\n",
    "        \"1. What is this dataset generally about? What kind of information does it contain?\\n\"\n",
    "        \"2. What are the likely column headers or categories of data visible?\\n\"\n",
    "        \"3. What fields qualify as column names, list these?\\n\"\n",
    "        \"4. Are there any obvious patterns, special values (like N/A, NULL), or characteristics you can infer from the visible data?\\n\"\n",
    "        \"Provide a concise summary based on your observations of the image.\"\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt_text,\n",
    "        \"images\": [base64_image_data],  # Ollama expects an array of base64 strings\n",
    "        \"stream\": False\n",
    "        # You can add \"options\" here if needed, e.g., \"options\": {\"temperature\": 0.3}\n",
    "    }\n",
    "\n",
    "    print(f\"\\nSending request to Ollama API at {ollama_url} with model {model_name}...\")\n",
    "    try:\n",
    "        response = requests.post(ollama_url, json=payload)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors (4xx or 5xx)\n",
    "\n",
    "        response_data = response.json()\n",
    "\n",
    "        if \"response\" in response_data:\n",
    "            print(\"\\n--- LLM Analysis Summary ---\")\n",
    "            print(response_data[\"response\"].strip())\n",
    "        elif \"error\" in response_data:\n",
    "            print(f\"\\nAPI Error from Ollama: {response_data['error']}\")\n",
    "            if \"model not found\" in response_data['error'].lower():\n",
    "                print(f\"Please ensure the model '{model_name}' is pulled in Ollama (e.g., 'ollama pull {model_name}') and Ollama is running.\")\n",
    "        else:\n",
    "            print(\"\\nReceived an unexpected response structure from Ollama:\")\n",
    "            print(json.dumps(response_data, indent=2))\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"\\nConnection Error: Could not connect to Ollama at {ollama_url}.\")\n",
    "        print(\"Please ensure Ollama is running and accessible.\")\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"\\nHTTP Error: {http_err}\")\n",
    "        try:\n",
    "            error_details = http_err.response.json()\n",
    "            print(f\"Error details from server: {json.dumps(error_details, indent=2)}\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Raw error response from server: {http_err.response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "# --- Run the analysis ---\n",
    "if __name__ == \"__main__\":\n",
    "    # IMPORTANT: Update IMAGE_FILE_PATH before running!\n",
    "    if IMAGE_FILE_PATH == 'path/to/your/dataset_screenshot.png' or not os.path.exists(IMAGE_FILE_PATH):\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(\"!!! IMPORTANT: Please update the 'IMAGE_FILE_PATH' variable in the   !!!\")\n",
    "        print(\"!!! script with the correct path to your dataset screenshot image.   !!!\")\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    else:\n",
    "        analyze_dataset_screenshot(IMAGE_FILE_PATH, OLLAMA_API_URL, MULTIMODAL_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV file from: your_data.csv\n",
      "ERROR: CSV file not found at 'your_data.csv'. Please check the path.\n",
      "Using a dummy DataFrame for demonstration purposes.\n",
      "Dummy DataFrame created.\n",
      "\n",
      "--- Requesting Data Cleanup Suggestions from CodeLlama ---\n",
      "\n",
      "Sending request to CodeLlama (codellama:7b at http://localhost:11434/api/chat)...\n",
      "\n",
      "--- CodeLlama's Data Cleanup Suggestions ---\n",
      "\n",
      "1. Potential data quality issues or inconsistencies:\n",
      "\t* Missing values in the \"col1\" column (5 rows with None)\n",
      "\t* Inconsistent data types for the \"numeric_col_as_str\" column (some values are strings, while others are floats)\n",
      "2. Recommended data cleaning steps:\n",
      "\t* Handling missing values: Replace any missing values in the \"col1\" column with a specific value (e.g., 0 or \"NA\") to avoid errors during analysis.\n",
      "\t* Correcting data types: Convert the \"numeric_col_as_str\" column to a numeric data type (e.g., float) to ensure consistent data types throughout the DataFrame.\n",
      "\t* Removing duplicates: Check for any duplicate rows in the DataFrame and remove them if necessary.\n",
      "\t* Standardizing formats: Ensure that all dates are in a standard format (e.g., YYYY-MM-DD) and convert any date strings to datetime objects.\n",
      "\t* Fixing inconsistencies: If there are any inconsistencies in the data, such as incorrect values or formatting issues, clean them up by correcting the data manually or using data validation techniques.\n",
      "\n",
      "--- Requesting Python Cleanup Code from CodeLlama ---\n",
      "\n",
      "Sending request to CodeLlama (codellama:7b at http://localhost:11434/api/chat)...\n",
      "\n",
      "--- CodeLlama's Generated Python Code for Cleanup ---\n",
      "# Handle missing values in the \"col1\" column by replacing them with 0\n",
      "df['col1'] = df['col1'].fillna(0)\n",
      "\n",
      "# Correct data types for the \"numeric_col_as_str\" column to ensure consistent data types throughout the DataFrame\n",
      "df['numeric_col_as_str'] = pd.to_numeric(df['numeric_col_as_str'], errors='coerce')\n",
      "\n",
      "# Remove duplicates from the DataFrame if necessary\n",
      "df = df.drop_duplicates()\n",
      "\n",
      "# Standardize formats for dates in the \"date_col\" column to ensure consistent data types throughout the DataFrame\n",
      "df['date_col'] = pd.to_datetime(df['date_col'])\n",
      "\n",
      "# Fix inconsistencies in the data by correcting any incorrect values or formatting issues manually or using data validation techniques\n",
      "\n",
      "--- IMPORTANT ---\n",
      "The Python code above was generated by an LLM. REVIEW IT CAREFULLY before execution.\n",
      "You would typically copy this code into a new cell to run it on your DataFrame.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import io # To represent DataFrame info as string\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Ollama/CodeLlama Endpoint Configuration\n",
    "BASE_URL = \"http://localhost:11434\"  # Or your CodeLlama server URL\n",
    "API_PATH = \"/api/chat\"              # Or \"/api/generate\" if you prefer\n",
    "CODELAMA_MODEL = \"codellama:7b\"     # Your specific CodeLlama model\n",
    "\n",
    "# 2. CSV File Path\n",
    "#    Replace 'your_data.csv' with the actual path to your CSV file.\n",
    "CSV_FILE_PATH = 'your_data.csv' # <--- !!! IMPORTANT: UPDATE THIS PATH !!!\n",
    "\n",
    "# --- Helper Function to Prepare DataFrame Info for LLM ---\n",
    "def get_dataframe_info_for_prompt(df, num_rows_to_show=5):\n",
    "    \"\"\"\n",
    "    Generates a string representation of DataFrame info (header, dtypes, head)\n",
    "    to be included in the LLM prompt.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return \"No DataFrame loaded.\"\n",
    "        \n",
    "    header = \", \".join(df.columns.tolist())\n",
    "    \n",
    "    dtypes_buffer = io.StringIO()\n",
    "    df.info(buf=dtypes_buffer)\n",
    "    dtypes_str = dtypes_buffer.getvalue()\n",
    "\n",
    "    sample_data_str = df.head(num_rows_to_show).to_string()\n",
    "\n",
    "    info = f\"The DataFrame has the following columns (Header): {header}\\n\\n\"\n",
    "    info += f\"Data Types and Non-Null Counts:\\n{dtypes_str}\\n\\n\"\n",
    "    info += f\"Here are the first {num_rows_to_show} rows of the data:\\n{sample_data_str}\\n\"\n",
    "    return info\n",
    "\n",
    "# --- Helper Function to Call CodeLlama ---\n",
    "def call_codellama(prompt_text, model_name, base_url, api_path):\n",
    "    \"\"\"Sends a prompt to CodeLlama and returns the response content.\"\"\"\n",
    "    endpoint_url = base_url + api_path\n",
    "    \n",
    "    if \"chat\" in api_path:\n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt_text}],\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                 \"temperature\": 0.2, # Lower temperature for more deterministic code/suggestions\n",
    "                 # \"num_predict\": 1024 # Adjust as needed for longer responses\n",
    "            }\n",
    "        }\n",
    "    else: # For /api/generate\n",
    "        payload = {\n",
    "            \"model\": model_name,\n",
    "            \"prompt\": prompt_text,\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                 \"temperature\": 0.2,\n",
    "                 # \"num_predict\": 1024\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    print(f\"\\nSending request to CodeLlama ({model_name} at {endpoint_url})...\")\n",
    "    # print(f\"Prompt snippet: {prompt_text[:200]}...\") # For debugging\n",
    "\n",
    "    response = requests.post(endpoint_url, json=payload, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "\n",
    "    if \"chat\" in api_path:\n",
    "        content = result.get(\"message\", {}).get(\"content\", \"\")\n",
    "    elif \"generate\" in api_path:\n",
    "        content = result.get(\"response\", \"\")\n",
    "    else:\n",
    "        content = json.dumps(result, indent=2)\n",
    "    \n",
    "    if not content.strip(): # Check if content is empty or just whitespace\n",
    "        print(\"Warning: Received empty content from CodeLlama.\")\n",
    "        # print(f\"Full response: {result}\") # For debugging\n",
    "    return content\n",
    "\n",
    "# --- Main Logic ---\n",
    "df_loaded = None\n",
    "try:\n",
    "    # 1. Load the CSV into a pandas DataFrame\n",
    "    print(f\"Loading CSV file from: {CSV_FILE_PATH}\")\n",
    "    try:\n",
    "        df_loaded = pd.read_csv(CSV_FILE_PATH)\n",
    "        print(\"CSV loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: CSV file not found at '{CSV_FILE_PATH}'. Please check the path.\")\n",
    "        # Create a dummy DataFrame for demonstration if file not found\n",
    "        print(\"Using a dummy DataFrame for demonstration purposes.\")\n",
    "        data = {'col1': [1, 2, None, 4, '  ', 6],\n",
    "                'col2': ['a', 'b', 'c', ' d ', 'e', 'a'],\n",
    "                'date_col': ['2023-01-01', '2023-01-02', '2023-01-03', '2023/01/04', 'invalid_date', '2023-01-01'],\n",
    "                'numeric_col_as_str': ['100', '200.5', '300', 'Nan', '500', '100'],\n",
    "                'id': [1,2,3,4,5,1]\n",
    "               }\n",
    "        df_loaded = pd.DataFrame(data)\n",
    "        print(\"Dummy DataFrame created.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"ERROR: The CSV file '{CSV_FILE_PATH}' is empty. Cannot proceed.\")\n",
    "        exit() # Or handle as appropriate\n",
    "\n",
    "    # 2. Get DataFrame information for the prompt\n",
    "    dataframe_details = get_dataframe_info_for_prompt(df_loaded, num_rows_to_show=3)\n",
    "\n",
    "    # --- STEP 1: Get Data Cleanup Suggestions ---\n",
    "    prompt_for_suggestions = (\n",
    "        f\"I have a pandas DataFrame, loaded from a CSV, with the following structure and sample data:\\n\\n\"\n",
    "        f\"{dataframe_details}\\n\\n\"\n",
    "        f\"Based on these column names, data types, and sample values, please describe in bullet points:\\n\"\n",
    "        f\"1. Potential data quality issues or inconsistencies you observe.\\n\"\n",
    "        f\"2. Specific data cleaning steps you would recommend to prepare this data for analysis (e.g., handling missing values, correcting data types, removing duplicates, standardizing formats, fixing inconsistencies).\\n\"\n",
    "        f\"Focus on actionable recommendations.\"\n",
    "    )\n",
    "    \n",
    "    print(\"\\n--- Requesting Data Cleanup Suggestions from CodeLlama ---\")\n",
    "    cleanup_suggestions = call_codellama(prompt_for_suggestions, CODELAMA_MODEL, BASE_URL, API_PATH)\n",
    "    \n",
    "    if not cleanup_suggestions.strip():\n",
    "        print(\"Failed to get cleanup suggestions from CodeLlama. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n--- CodeLlama's Data Cleanup Suggestions ---\")\n",
    "    print(cleanup_suggestions)\n",
    "\n",
    "    # --- STEP 2: Generate Python Code for Cleanup ---\n",
    "    prompt_for_code = (\n",
    "        f\"You are an expert Python programmer specializing in data cleaning with pandas.\\n\"\n",
    "        f\"I have a pandas DataFrame named `df` with the following structure and sample data:\\n\\n\"\n",
    "        f\"{dataframe_details}\\n\\n\"\n",
    "        f\"Based on the following data cleaning suggestions that were previously provided:\\n\"\n",
    "        f\"--- SUGGESTIONS ---\\n\"\n",
    "        f\"{cleanup_suggestions}\\n\"\n",
    "        f\"--- END SUGGESTIONS ---\\n\\n\"\n",
    "        f\"Please write a Python script using the pandas library to perform these cleaning operations on the DataFrame `df`.\\n\"\n",
    "        f\"Assume the DataFrame `df` is already loaded.\\n\"\n",
    "        f\"Provide only the Python code, preferably in a single block. Include comments in the code to explain each step.\\n\"\n",
    "        f\"If a suggestion is too vague or cannot be directly translated to code, you can make a reasonable assumption or note it in a comment.\\n\"\n",
    "        f\"For example, if a suggestion is 'Handle missing values in col1', you might fill with a mean, median, or a constant, and state your choice in a comment.\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Requesting Python Cleanup Code from CodeLlama ---\")\n",
    "    generated_python_code = call_codellama(prompt_for_code, CODELAMA_MODEL, BASE_URL, API_PATH)\n",
    "\n",
    "    print(\"\\n--- CodeLlama's Generated Python Code for Cleanup ---\")\n",
    "    # LLMs often wrap code in markdown backticks, try to extract if present\n",
    "    if \"```python\" in generated_python_code:\n",
    "        generated_python_code = generated_python_code.split(\"```python\\n\")[1].split(\"\\n```\")[0]\n",
    "    elif \"```\" in generated_python_code: # Simpler extraction if just ```\n",
    "         generated_python_code = generated_python_code.split(\"```\\n\")[1].split(\"\\n```\")[0]\n",
    "    print(generated_python_code)\n",
    "\n",
    "    # Note: The generated code is printed here.\n",
    "    # For actual execution, you would typically copy this code into a new cell,\n",
    "    # review it carefully, and then run it.\n",
    "    # DO NOT EXECUTE UNTRUSTED CODE AUTOMATICALLY.\n",
    "    print(\"\\n--- IMPORTANT ---\")\n",
    "    print(\"The Python code above was generated by an LLM. REVIEW IT CAREFULLY before execution.\")\n",
    "    print(\"You would typically copy this code into a new cell to run it on your DataFrame.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as fnf_error:\n",
    "    # This specific error is handled during df loading, but good to have a general catch\n",
    "    print(f\"File error: {fnf_error}\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Pandas EmptyDataError: The CSV file '{CSV_FILE_PATH}' might be empty or improperly formatted.\")\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "    if hasattr(http_err, 'response') and http_err.response is not None:\n",
    "        print(f\"Response content: {http_err.response.content.decode()}\")\n",
    "except requests.exceptions.ConnectionError as conn_err:\n",
    "    print(f\"Connection error: {conn_err}\")\n",
    "    print(f\"Please ensure your local CodeLlama endpoint is running and accessible at {BASE_URL}{API_PATH}.\")\n",
    "except requests.exceptions.RequestException as req_err:\n",
    "    print(f\"Request error occurred: {req_err}\")\n",
    "except json.JSONDecodeError as json_err:\n",
    "    print(f\"Failed to decode JSON response from CodeLlama: {json_err}\")\n",
    "    # Potentially print response.text if available and not too large\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to: http://localhost:11434/api/chat\n",
      "Payload: {\n",
      "  \"model\": \"codellama:7b\",\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Write a Python function that calculates the factorial of a number.\"\n",
      "    }\n",
      "  ],\n",
      "  \"stream\": false\n",
      "}\n",
      "\n",
      "Response from CodeLlama:\n",
      "[PYTHON]\n",
      "def calculate_factorial(n):\n",
      "    if n == 0:\n",
      "        return 1\n",
      "    else:\n",
      "        return n * calculate_factorial(n-1)\n",
      "[/PYTHON]\n",
      "[TESTS]\n",
      "# Test case 1:\n",
      "assert calculate_factorial(0) == 1\n",
      "# Test case 2:\n",
      "assert calculate_factorial(1) == 1\n",
      "# Test case 3:\n",
      "assert calculate_factorial(5) == 120\n",
      "# Test case 4:\n",
      "assert calculate_factorial(10) == 3628800\n",
      "[/TESTS]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 1. Define your local CodeLlama endpoint\n",
    "# If Ollama is running on the default port:\n",
    "BASE_URL = \"http://localhost:11434\"\n",
    "# API_PATH = \"/api/generate\" # For text generation\n",
    "API_PATH = \"/api/chat\"   # For chat-style completions\n",
    "\n",
    "# Or if you are using a different server (e.g., TGI on port 8080):\n",
    "# BASE_URL = \"http://localhost:8080\"\n",
    "# API_PATH = \"/generate\" # Or whatever your TGI endpoint path is\n",
    "\n",
    "ENDPOINT_URL = BASE_URL + API_PATH\n",
    "\n",
    "# 2. Prepare your payload (this depends on your CodeLlama endpoint's expected format)\n",
    "\n",
    "# Example for Ollama's /api/chat endpoint:\n",
    "payload = {\n",
    "    \"model\": \"codellama:7b\",  # Replace with your specific CodeLlama model name if different\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"write code to clean.\"}\n",
    "    ],\n",
    "    \"stream\": False, # Set to True if your endpoint supports it and you want to handle streaming\n",
    "    # \"options\": { # Optional parameters\n",
    "    #     \"temperature\": 0.7,\n",
    "    #     \"num_predict\": 200 # Max tokens\n",
    "    # }\n",
    "}\n",
    "\n",
    "# Example for Ollama's /api/generate endpoint (older style):\n",
    "# payload = {\n",
    "#     \"model\": \"codellama:7b\",\n",
    "#     \"prompt\": \"def python_function_to_add_two_numbers(a, b):\\n\",\n",
    "#     \"stream\": False\n",
    "# }\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(f\"Sending request to: {ENDPOINT_URL}\")\n",
    "print(f\"Payload: {json.dumps(payload, indent=2)}\")\n",
    "\n",
    "try:\n",
    "    response = requests.post(ENDPOINT_URL, json=payload, headers=headers)\n",
    "    response.raise_for_status()  # Raises an HTTPError for bad responses (4XX or 5XX)\n",
    "\n",
    "    # Process the response\n",
    "    result = response.json()\n",
    "    print(\"\\nResponse from CodeLlama:\")\n",
    "\n",
    "    if \"generate\" in API_PATH: # Typical for Ollama generate\n",
    "        print(result.get(\"response\"))\n",
    "    elif \"chat\" in API_PATH: # Typical for Ollama chat\n",
    "        if result.get(\"message\"):\n",
    "            print(result.get(\"message\", {}).get(\"content\"))\n",
    "        else: # Sometimes the full response for non-streaming chat is just the content\n",
    "            print(result)\n",
    "    else: # Adjust based on your specific endpoint's response structure\n",
    "        print(json.dumps(result, indent=2))\n",
    "\n",
    "\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "    print(f\"Response content: {response.content.decode()}\")\n",
    "except requests.exceptions.ConnectionError as conn_err:\n",
    "    print(f\"Connection error: {conn_err}\")\n",
    "    print(\"Please ensure your local CodeLlama endpoint is running and accessible at the specified URL.\")\n",
    "except requests.exceptions.RequestException as req_err:\n",
    "    print(f\"Request error occurred: {req_err}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Failed to decode JSON response.\")\n",
    "    print(f\"Response content: {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
